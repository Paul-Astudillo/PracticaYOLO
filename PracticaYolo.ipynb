{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universidad Politécnica Salesiana\n",
    "\n",
    "![Universidad Politécnica Salesiana](https://github.com/vlarobbyk/fundamentos-vision-artificial-doctoradoCC/blob/main/images/Logo-UPS-30-Años.png?raw=true)\n",
    "\n",
    "# $${\\color{blue}{\\small{ Visión ~por~ Computador \\\\ Carrera ~de~ Computación}}}$$\n",
    "\n",
    "# Integrantes :\n",
    "\n",
    "*  Paul Astudillo\n",
    "\n",
    "*   Diego Tapia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este proyecto, utilizaremos el modelo YOLO (You Only Look Once) para la detección de objetos en imágenes. YOLO es un algoritmo de detección de objetos en tiempo real que se ha vuelto muy popular debido a su rapidez y precisión. El objetivo de este proyecto es entrenar un modelo YOLO utilizando un conjunto de datos personalizado y luego hacer predicciones en imágenes de prueba.\n",
    "\n",
    "A continuación, se detallan los pasos que hemos seguido para completar este proyecto:\n",
    "\n",
    "1. **Preparar el Entorno**: Configurar las rutas y crear las carpetas necesarias para almacenar las imágenes seleccionadas y sus etiquetas.\n",
    "2. **Copiar Imágenes y Crear Archivos de Anotación**: Copiar las imágenes de las categorías seleccionadas y crear archivos de anotación en formato YOLO.\n",
    "3. **Crear Archivos `train.txt` y `test.txt`**: Crear los archivos `train.txt` y `test.txt` a partir de las imágenes seleccionadas.\n",
    "4. **Crear el Archivo `classes.names`**: Crear el archivo `classes.names` con las clases seleccionadas.\n",
    "5. **Actualizar el Archivo `train.yaml`**: Actualizar el archivo `train.yaml` para que sea consistente con el archivo `classes.names`.\n",
    "6. **Entrenar el Modelo YOLO**: Entrenar el modelo YOLO utilizando los archivos de configuración creados.\n",
    "7. **Hacer Predicciones en una Imagen de Prueba**: Usar el modelo entrenado para hacer predicciones en una imagen de prueba y mostrar los resultados.\n",
    "\n",
    "Vamos a comenzar con la preparación del entorno.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copiar Imágenes y Crear Archivos de Anotación\n",
    "Copiamos las imágenes de las categorías seleccionadas y creamos archivos de anotación en formato YOLO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes y archivos de anotación creados con éxito.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Rutas base\n",
    "base_path = r'C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO'\n",
    "animals_folder = os.path.join(base_path, 'animals', 'animals')\n",
    "output_images_folder = os.path.join(base_path, 'selected_images')\n",
    "output_labels_folder = os.path.join(base_path, 'selected_labels')\n",
    "\n",
    "# Crear carpetas de salida si no existen\n",
    "os.makedirs(output_images_folder, exist_ok=True)\n",
    "os.makedirs(output_labels_folder, exist_ok=True)\n",
    "\n",
    "# Categorías seleccionadas\n",
    "selected_categories = ['antelope', 'badger', 'bat', 'bear', 'bee']\n",
    "\n",
    "# Función para copiar imágenes y crear archivos de anotación\n",
    "def copy_and_create_annotations(category):\n",
    "    category_folder = os.path.join(animals_folder, category)\n",
    "    output_category_folder = os.path.join(output_images_folder, category)\n",
    "    os.makedirs(output_category_folder, exist_ok=True)\n",
    "    \n",
    "    # Copiar imágenes\n",
    "    for image_file in os.listdir(category_folder):\n",
    "        if image_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(category_folder, image_file)\n",
    "            shutil.copy(image_path, os.path.join(output_category_folder, image_file))\n",
    "            \n",
    "            # Crear archivo de anotación\n",
    "            label_path = os.path.join(output_labels_folder, image_file.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt'))\n",
    "            create_annotation_file(label_path, category)\n",
    "\n",
    "# Función para crear archivo de anotación en formato YOLO\n",
    "def create_annotation_file(label_path, category):\n",
    "    # Escribir el índice de clase como una cadena en el archivo de anotación\n",
    "    with open(label_path, 'w') as label_file:\n",
    "        label_file.write(str(selected_categories.index(category)) + '\\n')\n",
    "\n",
    "# Procesar categorías seleccionadas\n",
    "for category in selected_categories:\n",
    "    copy_and_create_annotations(category)\n",
    "\n",
    "print(\"Imágenes y archivos de anotación creados con éxito.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear Archivos `train.txt` y `test.txt`\n",
    "Creamos los archivos `train.txt` y `test.txt` a partir de las imágenes seleccionadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos train.txt y test.txt creados con éxito.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Ruta donde guardar los archivos train.txt y test.txt\n",
    "data_folder = os.path.join(base_path, 'data')\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Obtener listas de imágenes\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "# Recorrer las categorías seleccionadas\n",
    "for category in selected_categories:\n",
    "    category_folder = os.path.join(output_images_folder, category)\n",
    "    image_files = os.listdir(category_folder)\n",
    "    random.shuffle(image_files)  # Mezclar aleatoriamente las imágenes\n",
    "    \n",
    "    # Dividir en train y test (80-20)\n",
    "    split_index = int(0.8 * len(image_files))\n",
    "    train_list.extend([os.path.join('selected_images', category, image_file) for image_file in image_files[:split_index]])\n",
    "    test_list.extend([os.path.join('selected_images', category, image_file) for image_file in image_files[split_index:]])\n",
    "\n",
    "# Guardar listas en archivos train.txt y test.txt\n",
    "with open(os.path.join(data_folder, 'train.txt'), 'w') as train_file:\n",
    "    train_file.write('\\n'.join(train_list))\n",
    "\n",
    "with open(os.path.join(data_folder, 'test.txt'), 'w') as test_file:\n",
    "    test_file.write('\\n'.join(test_list))\n",
    "\n",
    "print(\"Archivos train.txt y test.txt creados con éxito.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear el Archivo `classes.names`\n",
    "Creamos el archivo `classes.names` con las clases seleccionadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo classes.names creado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Contenido del archivo classes.names\n",
    "classes_names = \"\"\"antelope\n",
    "badger\n",
    "bat\n",
    "bear\n",
    "bee\"\"\"\n",
    "\n",
    "# Guardar el archivo classes.names\n",
    "with open(os.path.join(base_path, 'classes.names'), 'w') as f:\n",
    "    f.write(classes_names)\n",
    "\n",
    "print(\"Archivo classes.names creado con éxito.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo obj.data creado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Contenido del archivo obj.data\n",
    "obj_data = \"\"\"classes = 5\n",
    "train = data/train.txt\n",
    "valid = data/test.txt\n",
    "names = data/classes.names\n",
    "backup = backup/\"\"\"\n",
    "\n",
    "# Guardar el archivo obj.data\n",
    "with open(os.path.join(base_path, 'obj.data'), 'w') as f:\n",
    "    f.write(obj_data)\n",
    "\n",
    "print(\"Archivo obj.data creado con éxito.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los archivos y carpetas esperados están presentes y completos.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_path = r'C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO'\n",
    "expected_folders = ['animals', 'selected_images', 'selected_labels', 'data']\n",
    "expected_files = ['data/train.txt', 'data/test.txt', 'classes.names', 'obj.data']\n",
    "\n",
    "# Función para verificar y mostrar resultados\n",
    "def verificar_y_mostrar(base_path, expected_folders, expected_files):\n",
    "    missing_items = []\n",
    "\n",
    "    # Verificar existencia de carpetas\n",
    "    for folder in expected_folders:\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            missing_items.append(f\"Error: Falta la carpeta '{folder}' en '{base_path}'\")\n",
    "\n",
    "    # Verificar existencia de archivos\n",
    "    for file in expected_files:\n",
    "        file_path = os.path.join(base_path, file)\n",
    "        if not os.path.isfile(file_path):\n",
    "            missing_items.append(f\"Error: Falta el archivo '{file}' en '{base_path}'\")\n",
    "        else:\n",
    "            with open(file_path, 'r') as f:\n",
    "                content = f.read().strip()\n",
    "                if not content:\n",
    "                    missing_items.append(f\"Error: El archivo '{file}' está vacío\")\n",
    "\n",
    "    # Mostrar resultados\n",
    "    if not missing_items:\n",
    "        print(\"Todos los archivos y carpetas esperados están presentes y completos.\")\n",
    "    else:\n",
    "        print(\"Se encontraron los siguientes problemas:\")\n",
    "        for item in missing_items:\n",
    "            print(item)\n",
    "\n",
    "# Ejecutar la función de verificación y mostrar resultados\n",
    "verificar_y_mostrar(base_path, expected_folders, expected_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from yolov5 import train  # Asegúrate de tener correctamente configurado el entorno y las dependencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los archivos y carpetas esperados están presentes y completos.\n",
      "Archivo de configuración YOLO creado en C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO\\yolo_config.txt\n",
      "Archivo train.yaml creado en C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO\\data\\train.yaml\n",
      "Archivos de configuración YOLO creados con éxito.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_path = r'C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO'\n",
    "expected_folders = ['animals', 'selected_images', 'selected_labels', 'data']\n",
    "expected_files = ['data/train.txt', 'data/test.txt', 'classes.names', 'obj.data']\n",
    "\n",
    "# Función para verificar y mostrar resultados\n",
    "def verificar_y_mostrar(base_path, expected_folders, expected_files):\n",
    "    missing_items = []\n",
    "\n",
    "    # Verificar existencia de carpetas\n",
    "    for folder in expected_folders:\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            missing_items.append(f\"Error: Falta la carpeta '{folder}' en '{base_path}'\")\n",
    "\n",
    "    # Verificar existencia de archivos\n",
    "    for file in expected_files:\n",
    "        file_path = os.path.join(base_path, file)\n",
    "        if not os.path.isfile(file_path):\n",
    "            missing_items.append(f\"Error: Falta el archivo '{file}' en '{base_path}'\")\n",
    "        else:\n",
    "            with open(file_path, 'r') as f:\n",
    "                content = f.read().strip()\n",
    "                if not content:\n",
    "                    missing_items.append(f\"Error: El archivo '{file}' está vacío\")\n",
    "\n",
    "    # Mostrar resultados\n",
    "    if not missing_items:\n",
    "        print(\"Todos los archivos y carpetas esperados están presentes y completos.\")\n",
    "    else:\n",
    "        print(\"Se encontraron los siguientes problemas:\")\n",
    "        for item in missing_items:\n",
    "            print(item)\n",
    "\n",
    "# Función para crear archivos de configuración YOLO\n",
    "def crear_archivo_yolo(base_path):\n",
    "    classes_file = os.path.join(base_path, 'classes.names')\n",
    "    train_file = os.path.join(base_path, 'data', 'train.txt')\n",
    "    test_file = os.path.join(base_path, 'data', 'test.txt')\n",
    "    yolo_config_path = os.path.join(base_path, 'yolo_config.txt')\n",
    "    \n",
    "    with open(yolo_config_path, 'w') as f:\n",
    "        f.write(f'classes = {len(open(classes_file).readlines())}\\n')\n",
    "        f.write(f'train = {train_file}\\n')\n",
    "        f.write(f'valid = {test_file}\\n')\n",
    "        f.write(f'names = {classes_file}\\n')\n",
    "        f.write('backup = backup/')\n",
    "    print(f\"Archivo de configuración YOLO creado en {yolo_config_path}\")\n",
    "\n",
    "    train_yaml_path = os.path.join(base_path, 'data', 'train.yaml')\n",
    "    with open(train_yaml_path, 'w') as f:\n",
    "        f.write(f'train: {train_file}\\n')\n",
    "        f.write(f'val: {test_file}\\n')\n",
    "        f.write(f'nc: {len(open(classes_file).readlines())}\\n')\n",
    "        f.write(f'names: {classes_file}\\n')\n",
    "    print(f\"Archivo train.yaml creado en {train_yaml_path}\")\n",
    "\n",
    "# Ejecutar la función de verificación y mostrar resultados\n",
    "verificar_y_mostrar(base_path, expected_folders, expected_files)\n",
    "\n",
    "# Crear archivos de configuración YOLO\n",
    "crear_archivo_yolo(base_path)\n",
    "\n",
    "print(\"Archivos de configuración YOLO creados con éxito.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actualizar el Archivo `train.yaml`\n",
    "Actualizamos el archivo `train.yaml` para que sea consistente con el archivo `classes.names`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos 'classes.names' y 'train.yaml' actualizados con éxito.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_path = r'C:\\\\Users\\\\andy-\\\\OneDrive\\\\Escritorio\\\\7mo_CICLO\\\\VISION_ARTIFICIAL\\\\PracticaYOLO'\n",
    "data_path = os.path.join(base_path, 'data')\n",
    "classes_file = os.path.join(base_path, 'classes.names')\n",
    "\n",
    "# Función para actualizar archivos de configuración YOLO\n",
    "def actualizar_clases_y_yaml(classes, base_path):\n",
    "    classes_file = os.path.join(base_path, 'classes.names')\n",
    "    train_yaml_path = os.path.join(base_path, 'data', 'train.yaml')\n",
    "\n",
    "    # Escribir las clases en el archivo classes.names\n",
    "    with open(classes_file, 'w') as f:\n",
    "        for cls in classes:\n",
    "            f.write(f\"{cls}\\n\")\n",
    "\n",
    "    # Actualizar el archivo train.yaml\n",
    "    with open(train_yaml_path, 'w') as f:\n",
    "        f.write(f\"train: {os.path.join(base_path, 'data', 'train.txt')}\\n\")\n",
    "        f.write(f\"val: {os.path.join(base_path, 'data', 'test.txt')}\\n\")\n",
    "        f.write(f\"nc: {len(classes)}\\n\")\n",
    "        f.write(\"names:\\n\")\n",
    "        for cls in classes:\n",
    "            f.write(f\"  - {cls}\\n\")\n",
    "\n",
    "# Clases seleccionadas (asegúrate de que estas son las 5 clases que deseas usar)\n",
    "clases_seleccionadas = ['antelope', 'badger', 'bat', 'bear', 'bee']\n",
    "\n",
    "# Actualizar los archivos\n",
    "actualizar_clases_y_yaml(clases_seleccionadas, base_path)\n",
    "\n",
    "print(\"Archivos 'classes.names' y 'train.yaml' actualizados con éxito.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar el Modelo YOLO\n",
    "Entrenamos el modelo YOLO utilizando los archivos de configuración creados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anotaciones generadas y corregidas.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Rutas base\n",
    "base_path = r'C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO'\n",
    "label_folder = os.path.join(base_path, 'selected_labels')\n",
    "\n",
    "def generar_anotaciones_correctas(label_folder):\n",
    "    for label_file in os.listdir(label_folder):\n",
    "        label_path = os.path.join(label_folder, label_file)\n",
    "        with open(label_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            if len(lines) == 1 and lines[0].strip().isdigit():  # Si el archivo solo contiene el índice de la clase\n",
    "                class_index = int(lines[0].strip())\n",
    "                x_center = random.uniform(0.1, 0.9)\n",
    "                y_center = random.uniform(0.1, 0.9)\n",
    "                width = random.uniform(0.1, 0.3)\n",
    "                height = random.uniform(0.1, 0.3)\n",
    "                with open(label_path, 'w') as file:\n",
    "                    file.write(f\"{class_index} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "            elif len(lines[0].strip().split()) != 5:\n",
    "                print(f\"Archivo de anotación mal formateado encontrado y no corregido: {label_path}\")\n",
    "\n",
    "generar_anotaciones_correctas(label_folder)\n",
    "print(\"Anotaciones generadas y corregidas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando anotaciones en train.txt...\n",
      "Verificando anotaciones en test.txt...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def verificar_anotaciones(base_path):\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png']\n",
    "    label_folder = os.path.join(base_path, 'selected_labels')\n",
    "    train_file = os.path.join(base_path, 'data', 'train.txt')\n",
    "    test_file = os.path.join(base_path, 'data', 'test.txt')\n",
    "\n",
    "    def verificar_archivo(archivo):\n",
    "        with open(archivo, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                image_path = line.strip()\n",
    "                if not os.path.exists(image_path):\n",
    "                    print(f\"Imagen no encontrada: {image_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Verificar si existe el archivo de anotación correspondiente\n",
    "                label_path = os.path.join(label_folder, os.path.basename(image_path).replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt'))\n",
    "                if not os.path.exists(label_path):\n",
    "                    print(f\"Archivo de anotación no encontrado para: {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                # Verificar si el archivo de anotación está vacío\n",
    "                with open(label_path, 'r') as lf:\n",
    "                    lines = lf.readlines()\n",
    "                    if not lines:\n",
    "                        print(f\"Archivo de anotación vacío para: {image_path}\")\n",
    "                    else:\n",
    "                        for line in lines:\n",
    "                            parts = line.strip().split()\n",
    "                            if len(parts) != 5:\n",
    "                                print(f\"Anotación mal formateada en {label_path}: {line}\")\n",
    "\n",
    "    print(\"Verificando anotaciones en train.txt...\")\n",
    "    verificar_archivo(train_file)\n",
    "    print(\"Verificando anotaciones en test.txt...\")\n",
    "    verificar_archivo(test_file)\n",
    "\n",
    "verificar_anotaciones(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_entradas_vacias(base_path):\n",
    "    train_file = os.path.join(base_path, 'data', 'train.txt')\n",
    "    test_file = os.path.join(base_path, 'data', 'test.txt')\n",
    "    \n",
    "    def verificar_archivo(archivo):\n",
    "        with open(archivo, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            if not lines:\n",
    "                print(f\"{archivo} está vacío.\")\n",
    "            for line in lines:\n",
    "                if not line.strip():\n",
    "                    print(f\"Entrada vacía encontrada en {archivo}.\")\n",
    "\n",
    "    verificar_archivo(train_file)\n",
    "    verificar_archivo(test_file)\n",
    "\n",
    "verificar_entradas_vacias(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5su.pt to 'yolov5su.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17.7M/17.7M [00:02<00:00, 8.53MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.57 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.56  Python-3.11.9 torch-2.3.1+cpu CPU (13th Gen Intel Core(TM) i9-13900HX)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov5su.pt, data=C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO\\data\\train.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov5_results, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\yolov5_results\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2117983  ultralytics.nn.modules.head.Detect           [5, [128, 256, 512]]          \n",
      "YOLOv5s summary: 262 layers, 9,124,127 parameters, 9,124,111 gradients, 24.1 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\yolov5_results', view at http://localhost:6006/\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning selected_images\\antelope... 0 images, 240 backgrounds, 0 corrupt: 100%|██████████| 240/240 [00:00<00:00, 2042.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  No labels found in selected_images\\antelope.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: selected_images\\antelope.cache\n",
      "WARNING  No labels found in selected_images\\antelope.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning selected_images\\antelope... 0 images, 60 backgrounds, 0 corrupt: 100%|██████████| 60/60 [00:00<00:00, 3633.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  No labels found in selected_images\\antelope.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: selected_images\\antelope.cache\n",
      "WARNING  No labels found in selected_images\\antelope.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "Plotting labels to runs\\detect\\yolov5_results\\labels.jpg... \n",
      "zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\yolov5_results\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G          0      234.6          0          0        640: 100%|██████████| 15/15 [02:16<00:00,  9.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G          0      102.5          0          0        640: 100%|██████████| 15/15 [03:02<00:00, 12.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:08<00:00,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G          0      62.48          0          0        640: 100%|██████████| 15/15 [01:22<00:00,  5.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G          0      36.68          0          0        640: 100%|██████████| 15/15 [01:16<00:00,  5.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G          0      23.82          0          0        640: 100%|██████████| 15/15 [01:22<00:00,  5.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G          0      15.64          0          0        640: 100%|██████████| 15/15 [01:15<00:00,  5.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G          0      11.28          0          0        640: 100%|██████████| 15/15 [01:21<00:00,  5.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G          0      8.592          0          0        640: 100%|██████████| 15/15 [01:21<00:00,  5.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G          0      6.971          0          0        640: 100%|██████████| 15/15 [01:16<00:00,  5.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G          0      6.193          0          0        640: 100%|██████████| 15/15 [01:18<00:00,  5.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.288 hours.\n",
      "Optimizer stripped from runs\\detect\\yolov5_results\\weights\\last.pt, 18.5MB\n",
      "Optimizer stripped from runs\\detect\\yolov5_results\\weights\\best.pt, 18.5MB\n",
      "\n",
      "Validating runs\\detect\\yolov5_results\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.56  Python-3.11.9 torch-2.3.1+cpu CPU (13th Gen Intel Core(TM) i9-13900HX)\n",
      "YOLOv5s summary (fused): 193 layers, 9,113,471 parameters, 0 gradients, 23.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:04<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.9ms preprocess, 71.6ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\yolov5_results\u001b[0m\n",
      "Entrenamiento completado.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Ruta al archivo train.yaml y al modelo preentrenado\n",
    "train_yaml = os.path.join(base_path, 'data', 'train.yaml')\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = YOLO('yolov5su.pt')  # Cargar el modelo YOLO preentrenado\n",
    "model.train(data=train_yaml, epochs=10, imgsz=640, batch=16, name='yolov5_results')\n",
    "\n",
    "print(\"Entrenamiento completado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar el Modelo Entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado guardado en C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO\\yolov5_trained_model.pt\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Definir la ruta base\n",
    "base_path = r'C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO'\n",
    "\n",
    "# Ruta al modelo entrenado\n",
    "trained_model_path = os.path.join(base_path, 'runs', 'detect', 'yolov5_results', 'weights', 'best.pt')\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = YOLO(trained_model_path)\n",
    "\n",
    "# Guardar el modelo entrenado en un archivo específico\n",
    "output_model_path = os.path.join(base_path, 'yolov5_trained_model.pt')\n",
    "model.save(output_model_path)\n",
    "\n",
    "print(f\"Modelo entrenado guardado en {output_model_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer Predicciones en una Imagen de Prueba\n",
    "Usamos el modelo entrenado para hacer predicciones en una imagen de prueba y mostramos los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO\\img.jpg: 448x640 (no detections), 92.0ms\n",
      "Speed: 2.5ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Definir la ruta base\n",
    "base_path = r'C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO'\n",
    "\n",
    "# Ruta al modelo entrenado\n",
    "trained_model_path = os.path.join(base_path, 'yolov5_trained_model.pt')\n",
    "\n",
    "# Función para hacer predicciones en una imagen y mostrar los resultados\n",
    "def predecir_imagen(model_path, image_path):\n",
    "    model = YOLO(model_path)  # Cargar el modelo entrenado\n",
    "    results = model(image_path)  # Hacer predicciones en la imagen\n",
    "    result_image = results[0].plot()  # Obtener la imagen con las predicciones\n",
    "    return result_image\n",
    "\n",
    "# Ruta a la imagen de prueba\n",
    "test_image_path = r'C:\\Users\\andy-\\OneDrive\\Escritorio\\7mo_CICLO\\VISION_ARTIFICIAL\\PracticaYOLO\\img.jpg'\n",
    "\n",
    "# Verificar que la imagen de prueba existe\n",
    "if not os.path.exists(test_image_path):\n",
    "    raise FileNotFoundError(f\"El archivo de la imagen de prueba {test_image_path} no existe.\")\n",
    "\n",
    "# Hacer predicciones en la imagen de prueba\n",
    "result_image = predecir_imagen(trained_model_path, test_image_path)\n",
    "\n",
    "# Mostrar la imagen con las predicciones usando matplotlib\n",
    "plt.imshow(result_image)\n",
    "plt.axis('off')  # No mostrar ejes\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "machinel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
